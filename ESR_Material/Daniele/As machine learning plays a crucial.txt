As machine learning plays a crucial role in many applications and is indispensable for many scientific, economic, and governmental activities, we should not neglect the immense risks of fraudulent activity, and we need to reinforce such systems with secure learning algorithms and practices. The necessity of operating machine learning models in adversarial environments, where an adversary actively works to have the implemented model behave differently from what it was defined for, led to the creation of a new research field called Adversarial Machine Learning (AML). Over the last two decades, adversarial machine learning has become a research topic of increasingly growing interest, mainly due to the significant initial results obtained in the field of image recognition. Despite the successful application of adversarial techniques to image recognition, generalizing them to other applications and domains is neither trivial nor obvious. This can have severe implications, as it leaves us oblivious to the effective threats that could hinder other applications, thus making it impossible to defend against them. In this paper, we consider the problem of applying adversarial machine learning techniques to fraud detection to ensure the robustness of online transaction systems against hostile attacks, describe how attacks against fraud detection systems differ from other applications of adversarial machine learning and propose several interesting directions to bridge this gap.